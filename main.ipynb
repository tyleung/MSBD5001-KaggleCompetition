{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbhYzIJvJlLg"
   },
   "source": [
    "# 2018-11-19 (3.91929)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4sieqmBJlLk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(0)\n",
    "from tensorflow.keras import layers, regularizers, optimizers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3osJJrEJlLs"
   },
   "outputs": [],
   "source": [
    "def readDataset(filename):\n",
    "    return pd.read_csv(filename, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTkm3nvuJlLy"
   },
   "outputs": [],
   "source": [
    "def preprocessDataset(dataset, is_test=False):\n",
    "    # Convert categorical variables to numerical\n",
    "    ohe = OneHotEncoder()\n",
    "    dataset = pd.get_dummies(dataset)\n",
    "    \n",
    "    dataset = dataset.drop([\"id\", \"l1_ratio\", \"scale\", \"alpha\"], axis=1)        \n",
    "    dataset.loc[dataset[\"n_jobs\"] == -1, [\"n_jobs\"]] = 16\n",
    "        \n",
    "    #max_iter_n_samples = dataset[\"max_iter\"].values * dataset[\"n_samples\"].values * dataset[\"n_features\"].values\n",
    "    #dataset[\"max_iter_n_samples_n_features\"] = max_iter_n_samples\n",
    "    #dataset[\"max_iter_n_samples_n_features\"] /= dataset[\"n_jobs\"]\n",
    "    # dataset = dataset.drop([\"max_iter\", \"n_samples\", \"n_features\"], axis=1)\n",
    "    #n_informative_classes = dataset[\"n_informative\"].values * dataset[\"n_classes\"]\n",
    "    #dataset[\"n_informative_classes\"] = n_informative_classes / dataset[\"n_jobs\"]\n",
    "    max_iter_n_samples = dataset[\"max_iter\"].values * dataset[\"n_samples\"].values\n",
    "    dataset[\"max_iter_n_samples\"] = max_iter_n_samples\n",
    "    \n",
    "    # this is bad\n",
    "    #dataset[\"max_iter\"] /= dataset[\"n_jobs\"]\n",
    "    #dataset[\"n_samples\"] /= dataset[\"n_jobs\"]\n",
    "    #dataset[\"n_features\"] /= dataset[\"n_jobs\"]\n",
    "    #dataset[\"n_classes\"] /= dataset[\"n_jobs\"]\n",
    "    \n",
    "    # Remove outliers\n",
    "    if not is_test:\n",
    "        z = np.abs(zscore(dataset.drop([\"time\"], axis=1)))\n",
    "        dataset = dataset[(z < 3).all(axis=1)]\n",
    "    \n",
    "    time = None\n",
    "    if \"time\" in dataset.columns:\n",
    "        time = dataset[\"time\"]\n",
    "        dataset = dataset.drop([\"time\"], axis=1)\n",
    "        \n",
    "    # Z-score normalization\n",
    "    dataset = dataset.apply(zscore)\n",
    "\n",
    "    return dataset, time\n",
    "  \n",
    "def testPreprocessDataset(dataset):\n",
    "    dataset = dataset.drop([\"id\", \"l1_ratio\", \"alpha\", \"random_state\", \"n_clusters_per_class\", \"scale\"], axis=1)\n",
    "    dataset.loc[dataset[\"n_jobs\"] == -1, [\"n_jobs\"]] = 16\n",
    "    #dataset = dataset[dataset[\"flip_y\"] < 0.095]\n",
    "    \n",
    "    time = None\n",
    "    if \"time\" in dataset.columns:\n",
    "        time = dataset[\"time\"]\n",
    "        dataset = dataset.drop([\"time\"], axis=1)\n",
    "        \n",
    "    ohe = OneHotEncoder()\n",
    "    dataset = pd.get_dummies(dataset)\n",
    "    dataset = dataset.apply(zscore)\n",
    "    return dataset, time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOCuWQjoJlL8"
   },
   "outputs": [],
   "source": [
    "def plot_corr(dataset, target, size=10):\n",
    "    dataset_copy = dataset.copy(deep=True)\n",
    "    if \"time\" not in dataset_copy.columns:\n",
    "        dataset_copy[\"time\"] = target\n",
    "    corr = dataset_copy.corr()\n",
    "    return corr.style.background_gradient()\n",
    "    #corr = dataset.corrwith(target)\n",
    "    #return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "ev4OXTU2JlMB",
    "outputId": "387921ac-35bb-4cb1-b8a0-1dd5e82cf687"
   },
   "outputs": [],
   "source": [
    "# Read in the dataset\n",
    "df_full = readDataset(\"./train-combined.csv\")\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "zMnmcYhkRArY",
    "outputId": "2874beec-e5c9-4a53-ae72-2722b128a780"
   },
   "outputs": [],
   "source": [
    "# featexp\n",
    "\"\"\"\n",
    "from featexp import get_univariate_plots, get_trend_stats\n",
    "\n",
    "df_full = readDataset(\"/content/drive/My Drive/School/HKUST/MSBD 5001/KaggleCompetition/train-combined.csv\")\n",
    "df_full = df_full.drop([\"id\", \"l1_ratio\", \"alpha\", \"random_state\", \"n_clusters_per_class\", \"scale\"], axis=1)\n",
    "df_full.loc[df_full[\"n_jobs\"] == -1, [\"n_jobs\"]] = 16\n",
    "ohe = OneHotEncoder()\n",
    "df_full = pd.get_dummies(df_full)\n",
    "X_train, X_test = train_test_split(df_full, test_size=0.25)\n",
    "\n",
    "#df_full = df_full[df_full[\"flip_y\"] < 0.09]\n",
    "\n",
    "# Plots drawn for all features if nothing is passed in feature_list parameter.\n",
    "#get_univariate_plots(data=df_full, target_col='time', bins=20, features_list=['scale'])\n",
    "get_univariate_plots(data=X_train, target_col='time', bins=20, features_list=['flip_y'], data_test=X_test)\n",
    "\n",
    "#get_trend_stats(data=X_train, target_col='time', data_test=X_test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WoU2H5aJlMJ"
   },
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plot_corr(df_full.drop(\"id\", axis=1), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "Ccvjw08DJlMS",
    "outputId": "1b9ca809-e360-433d-b6fd-1b876ccaad3e"
   },
   "outputs": [],
   "source": [
    "df, time = preprocessDataset(df_full)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWK34HxAJlMd"
   },
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plot_corr(df, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "hg2BEhc0JlMq",
    "outputId": "5ec397a8-58ac-4ce1-d99e-bdd7ff222251"
   },
   "outputs": [],
   "source": [
    "X = df.values\n",
    "y = time.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qux62R4M0Kbx"
   },
   "outputs": [],
   "source": [
    "# Keras sequential model\n",
    "def build_model():\n",
    "    num_units = 9\n",
    "    model = tf.keras.Sequential([\n",
    "      layers.Dense(num_units, kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
    "      #layers.Dense(num_units//2, kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
    "      #layers.Dense(num_units//4, kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
    "      #layers.Dropout(0.2),\n",
    "        \n",
    "      # Add a layer with 1 output unit:\n",
    "      layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "    #model.compile(optimizer=optimizers.Adam(lr=0.001, decay=0.01, amsgrad=True),\n",
    "    #model.compile(optimizer=tf.train.AdagradOptimizer(0.01),\n",
    "                  loss='mse',       # mean squared error\n",
    "                  metrics=['mse'])  # mean squared error\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 14982
    },
    "colab_type": "code",
    "id": "bjiYD0xMJlMz",
    "outputId": "75e9c143-de0c-4db0-bbaa-2c9aeee26d66"
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "history = model.fit(X, y, epochs=40, batch_size=9)\n",
    "                    #validation_data=(X_test, y_test),\n",
    "                    #validation_split=0.2)\n",
    "                    #verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "I8a_Lgn_JlM6",
    "outputId": "c3d43c95-e38d-4c7b-fd5f-4874bbba7281"
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy  \n",
    "plt.plot(history.history['mean_squared_error'][:])  \n",
    "plt.plot(history.history['val_mean_squared_error'][:])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKUV8iORJlNE"
   },
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "df_test = readDataset(\"./test.csv\")\n",
    "df_test, time = preprocessDataset(df_test, True)\n",
    "#df_test.head()\n",
    "X_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAYmCvhVJlNH"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mVs9G1qJlNN"
   },
   "outputs": [],
   "source": [
    "# Output to csv\n",
    "import datetime\n",
    "d = datetime.datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "output = pd.DataFrame(data=y_pred, columns=[\"time\"])\n",
    "output[\"time\"] = output[\"time\"].abs()\n",
    "\n",
    "filename = \"./submission-\" + d + \".csv\"\n",
    "output.to_csv(filename, index_label=\"Id\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2018-11-16.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
